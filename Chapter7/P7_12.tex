\unless\ifdefined\IsMainDocument
\documentclass[12pt]{article}
\usepackage{amsmath,amsthm,amssymb}
\newcommand{\A}{\mathcal{A}}
\newcommand{\Fhat}{\widehat{F}}
\newcommand{\Ghat}{\widehat{G}}
\begin{document}
\fi

\textbf{Problem 7.12}: (Generalized divisor function.) For $c$ a fixed real number, not 0 or a negative integer, define a multiplicative function $\tau_c$ by setting
$$\tau_c(p^j) = c (c + 1) \cdots (c + j - 1)/j!$$
for primes $p$ and positive integers $j$. Find an assymptotic formula for the associated summatory function. (Cf. Problem 3.26.)

\begin{proof}
Let $F_c$ be the summatory function of $\tau_c$.

\noindent \textbf{The case $c > 0$:} We consider the case $c > 0$ so that $\tau_c > 0$ and $F_c$ is monotone nondecreasing. Also observe that if $c < d$ then $\tau_c < \tau_d$ and so $F_c < F_d$. It is easy to check\footnote{Both are multiplicative and they agree on prime powers.} that $\tau_k = 1^{*k}$ for positive integer $k$ and we already have bound $F_k = O(x^{1 + \epsilon})$ for all positive integer $k$ (albeit not uniformly) thank to Problem 3.26. It follows that $F_c = O(F_{[c] + 1}) = O(x^{1 + \epsilon})$ for all $c > 0$ which implies $\sigma_c(F_c) = \sigma_a(F_c) \leq 1$. In other words, $\Fhat_c$ converges absolutely for $\sigma > 1$ and we have the Euler product there.

Notice that the function $h(x) = x^{-c}$ have higher derivatives
\begin{align*}
h_c^{(j)}(x) &= (-c) (-c - 1) ... (-c - j + 1) x^{- c - j}\\
&= (-1)^j c (c + 1) ... (c + j - 1) x^{- c - j}
\end{align*}
and thus Taylor expansion
$$h_c(x) = \sum_{j = 0}^{\infty} c (c + 1) ... (c + j - 1) \frac{(1 - x)^j}{j!}$$
which converges at least when $|x - 1| < 1$ (i.e. when $\lim_{j \rightarrow \infty} \frac{(c+j) |1-x|}{1 + j} < 1$ so ratio test applies).

Hence, we have
\begin{align*}
\Fhat_c(s) &= \prod_p \left(\sum_{j = 0}^{\infty} \frac{c (c + 1) \cdots (c + j - 1)}{j!} p^{-js}\right) & (\sigma > 1) \\
&= \prod_p h_c(1 - p^{-s})\\
&= \prod_p (1 - p^{-s})^{-c} \\
&= \zeta(s)^c \\
&= (s - 1)^{-c} \; ((s - 1)\zeta(s))^c
\end{align*}
so just like the previous problem: This formula shows that $\sigma_c(\Fhat_c) = 1$ (due to the pole of $\zeta$ and Problem 6.18) and $\Fhat_c$ satisfies the hypothesis of the generalized Wiener-Ikehara theorem with
$$\varphi(s) = ((s - 1)\zeta(s))^c$$
analytic on $\{ \sigma > 0 \}$. By the theorem, we have
$$F_c(x) = \sum_{n \leq x} \tau_c(n) \sim \frac{x (\log x)^{c - 1}}{\Gamma(c)}.$$

\textbf{Note}: If we do not want to use Problem 3.26, we can bootstrap the proof by solving this problem for $c = k$ being positive integers first: Theorem 6.2 gives us $\Fhat_k(s) = \zeta(s)^k$ for $\sigma > 1$ immediately thank to the representation $\tau_k = 1^{*k}$ even though we do not know $\sum_{n \leq x} \tau_k(n) = O(x^{1 + \epsilon})$. This implies $\sigma_c(\Fhat_k) = 1$ and we apply the generalized Wiener-Ikehara theorem just like the case for general $c > 0$.

\noindent \textbf{The case $c < 0$:} When $c < 0$, this argument does not work because the function $F_c$ is not monotone as $\tau_c(n)$ can oscillate between negative (when $n$ is a prime number and there are infinitely many such $n$) and positive values (when $n = p^2$, $\tau_c(p^2) = c^2 > 0$).

However, we can determine the right abscissa of convergence of $\Fhat_c(s)$ because of the assumption that $c$ is not 0 or a negative integer.

First, let us show that $\sigma_c(\Fhat_c) \leq 1$. It is clear that
$$|c + k| \leq |c| + k = -c + k$$
so
$$|\tau_c(p^j)| \leq \tau_{-c}(p^j)$$
for all prime $p$ and all integer $j \geq 0$. This implies
$$|\tau_c(n)| \leq \tau_{-c}(n)$$
for all integer $n$ so $|F_c(x)| \leq F_{-c}(x)$ and since we already know $F_{-c}(x) = O(x^{1 + \epsilon})$, it follows that $\Fhat_c(s)$ converes absolutely for $\sigma > 1$. So $\sigma_c \leq 1$. With absolute convergence, the Euler product formula above still holds and we also have
$$\Fhat_c(s) = \zeta(s)^c \qquad (\sigma > 1).$$

From the above equation, we can see that $\Fhat_c(s)$ has a zero of non--integral order $-c$ at 1. So let $N$ be any (positive) integer exceeding $-c$ then $\Fhat_c^{(N)}(s)$ has a pole at $s = 1$ (of order $N + c$) by apply repeatedly the observation that if $f(s)$ is analytic with a zero of order $\alpha > 0$ at $s_0$ where $\alpha \not= 1$ then $f'(s)$ has either a zero of order $\alpha - 1$ (if $\alpha > 1$) or a pole of order $1 - \alpha$ (if $\alpha < 1$)
\footnote{To see this observation, we can write $f(s) = (s - s_0)^\alpha g(s)$ with $g$ analytic and $g(s_0) \not= 0$. Then $f'(s) = \alpha (s - s_0)^{\alpha - 1} g(s) + (s - s_0)^\alpha g'(s) = (s - s_0)^{\alpha - 1} \{ \alpha g(s) + (s - s_0) g'(\alpha) \}$. The analytic function in the curly braces clearly does not vanish at $s_0$. We are also using the fact that if $f(s)$ has a pole of order $\alpha$ at $s_0$ then $f'(s)$ has a pole of order $\alpha + 1$ at $s_0$.}.
If $\sigma_c < 1$ then $\Fhat_c^{(N)}(s)$ is analytic at $s = 1$ by Theorem 6.20, a contradiction. So $\sigma_c = 1$.

\textbf{Reference}: The asymptotic formula even for complex value of $c$ was in the paper of A. Selberg, \textit{Note on a paper by L. G. Sathe}.
\end{proof}

\unless\ifdefined\IsMainDocument
\end{document}
\fi
